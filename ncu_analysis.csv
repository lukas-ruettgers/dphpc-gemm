"ID","Process ID","Process Name","Host Name","Kernel Name","Context","Stream","Block Size","Grid Size","Device","CC","Section Name","Body Item Label","Metric Name","Metric Unit","Metric Value","Rule Name","Rule Type","Rule Description","Estimated Speedup Type","Estimated Speedup"
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On DFMA Thread Instructions Executed","inst/cycle","72",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On FFMA Thread Instructions Executed","inst/cycle","4608",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On DFMA Thread Instructions Executed Per Cycle","inst/cycle","0",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On FFMA Thread Instructions Executed Per Cycle","inst/cycle","407.84",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical Predicated-On FFMA Operations","inst","9216",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","SM Frequency","Ghz","2.40",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","DRAM Frequency","Ghz","13.79",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical Predicated-On DFMA Operations","inst","144",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","SM Frequency","Ghz","2.40",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","DRAM Frequency","Ghz","13.79",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FFMA Operations Per Cycle","inst","815.68",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","SM Frequency","Ghz","2.40",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FADD Thread Instructions Executed Per Cycle","inst/cycle","101.96",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FMUL Thread Instructions Executed Per Cycle","inst/cycle","12.75",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.56",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DFMA Operations Per Cycle","inst","0",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","SM Frequency","Ghz","2.40",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DADD Thread Instructions Executed Per Cycle","inst/cycle","0",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DMUL Thread Instructions Executed Per Cycle","inst/cycle","0",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.56",
"0","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved 10% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On DFMA Thread Instructions Executed","inst/cycle","72",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On FFMA Thread Instructions Executed","inst/cycle","4608",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On DFMA Thread Instructions Executed Per Cycle","inst/cycle","0",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On FFMA Thread Instructions Executed Per Cycle","inst/cycle","409.06",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical Predicated-On FFMA Operations","inst","9216",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","SM Frequency","Ghz","2.40",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","DRAM Frequency","Ghz","13.79",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical Predicated-On DFMA Operations","inst","144",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","SM Frequency","Ghz","2.40",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","DRAM Frequency","Ghz","13.79",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FFMA Operations Per Cycle","inst","818.13",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","SM Frequency","Ghz","2.40",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FADD Thread Instructions Executed Per Cycle","inst/cycle","102.27",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FMUL Thread Instructions Executed Per Cycle","inst/cycle","12.78",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.90",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DFMA Operations Per Cycle","inst","0",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","SM Frequency","Ghz","2.40",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DADD Thread Instructions Executed Per Cycle","inst/cycle","0",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DMUL Thread Instructions Executed Per Cycle","inst/cycle","0",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.90",
"1","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved 10% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On DFMA Thread Instructions Executed","inst/cycle","72",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On FFMA Thread Instructions Executed","inst/cycle","4608",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On DFMA Thread Instructions Executed Per Cycle","inst/cycle","0",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On FFMA Thread Instructions Executed Per Cycle","inst/cycle","408.02",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical Predicated-On FFMA Operations","inst","9216",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","SM Frequency","Ghz","2.40",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","DRAM Frequency","Ghz","13.79",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical Predicated-On DFMA Operations","inst","144",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","SM Frequency","Ghz","2.40",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","DRAM Frequency","Ghz","13.79",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FFMA Operations Per Cycle","inst","816.04",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","SM Frequency","Ghz","2.40",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FADD Thread Instructions Executed Per Cycle","inst/cycle","102.00",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FMUL Thread Instructions Executed Per Cycle","inst/cycle","12.75",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","DRAM Bandwidth","Gbyte/s","97.90",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DFMA Operations Per Cycle","inst","0",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","SM Frequency","Ghz","2.40",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DADD Thread Instructions Executed Per Cycle","inst/cycle","0",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DMUL Thread Instructions Executed Per Cycle","inst/cycle","0",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","DRAM Bandwidth","Gbyte/s","97.90",
"2","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved 10% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On DFMA Thread Instructions Executed","inst/cycle","72",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On FFMA Thread Instructions Executed","inst/cycle","4608",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On DFMA Thread Instructions Executed Per Cycle","inst/cycle","0",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On FFMA Thread Instructions Executed Per Cycle","inst/cycle","408.42",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical Predicated-On FFMA Operations","inst","9216",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","SM Frequency","Ghz","2.40",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","DRAM Frequency","Ghz","13.79",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical Predicated-On DFMA Operations","inst","144",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","SM Frequency","Ghz","2.40",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","DRAM Frequency","Ghz","13.79",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FFMA Operations Per Cycle","inst","816.84",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","SM Frequency","Ghz","2.40",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FADD Thread Instructions Executed Per Cycle","inst/cycle","102.11",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FMUL Thread Instructions Executed Per Cycle","inst/cycle","12.76",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.66",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DFMA Operations Per Cycle","inst","0",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","SM Frequency","Ghz","2.40",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DADD Thread Instructions Executed Per Cycle","inst/cycle","0",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DMUL Thread Instructions Executed Per Cycle","inst/cycle","0",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.66",
"3","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved 10% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On DFMA Thread Instructions Executed","inst/cycle","72",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On FFMA Thread Instructions Executed","inst/cycle","4608",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On DFMA Thread Instructions Executed Per Cycle","inst/cycle","0",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On FFMA Thread Instructions Executed Per Cycle","inst/cycle","408.65",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical Predicated-On FFMA Operations","inst","9216",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","SM Frequency","Ghz","2.40",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","DRAM Frequency","Ghz","13.79",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical Predicated-On DFMA Operations","inst","144",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","SM Frequency","Ghz","2.40",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","DRAM Frequency","Ghz","13.79",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FFMA Operations Per Cycle","inst","817.31",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","SM Frequency","Ghz","2.40",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FADD Thread Instructions Executed Per Cycle","inst/cycle","102.16",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FMUL Thread Instructions Executed Per Cycle","inst/cycle","12.77",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","DRAM Bandwidth","Gbyte/s","99.81",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DFMA Operations Per Cycle","inst","0",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","SM Frequency","Ghz","2.40",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DADD Thread Instructions Executed Per Cycle","inst/cycle","0",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DMUL Thread Instructions Executed Per Cycle","inst/cycle","0",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","DRAM Bandwidth","Gbyte/s","99.81",
"4","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved 10% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On DFMA Thread Instructions Executed","inst/cycle","72",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On FFMA Thread Instructions Executed","inst/cycle","4608",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On DFMA Thread Instructions Executed Per Cycle","inst/cycle","0",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On FFMA Thread Instructions Executed Per Cycle","inst/cycle","409.93",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical Predicated-On FFMA Operations","inst","9216",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","SM Frequency","Ghz","2.40",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","DRAM Frequency","Ghz","13.79",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical Predicated-On DFMA Operations","inst","144",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","SM Frequency","Ghz","2.40",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","DRAM Frequency","Ghz","13.79",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FFMA Operations Per Cycle","inst","819.86",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","SM Frequency","Ghz","2.40",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FADD Thread Instructions Executed Per Cycle","inst/cycle","102.48",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FMUL Thread Instructions Executed Per Cycle","inst/cycle","12.81",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","DRAM Bandwidth","Gbyte/s","100.21",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DFMA Operations Per Cycle","inst","0",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","SM Frequency","Ghz","2.40",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DADD Thread Instructions Executed Per Cycle","inst/cycle","0",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DMUL Thread Instructions Executed Per Cycle","inst/cycle","0",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","DRAM Bandwidth","Gbyte/s","100.21",
"5","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved 10% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On DFMA Thread Instructions Executed","inst/cycle","72",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On FFMA Thread Instructions Executed","inst/cycle","4608",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On DFMA Thread Instructions Executed Per Cycle","inst/cycle","0",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On FFMA Thread Instructions Executed Per Cycle","inst/cycle","407.73",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical Predicated-On FFMA Operations","inst","9216",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","SM Frequency","Ghz","2.40",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","DRAM Frequency","Ghz","13.79",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical Predicated-On DFMA Operations","inst","144",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","SM Frequency","Ghz","2.40",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","DRAM Frequency","Ghz","13.79",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FFMA Operations Per Cycle","inst","815.45",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","SM Frequency","Ghz","2.40",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FADD Thread Instructions Executed Per Cycle","inst/cycle","101.93",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FMUL Thread Instructions Executed Per Cycle","inst/cycle","12.74",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.40",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DFMA Operations Per Cycle","inst","0",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","SM Frequency","Ghz","2.40",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DADD Thread Instructions Executed Per Cycle","inst/cycle","0",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DMUL Thread Instructions Executed Per Cycle","inst/cycle","0",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.40",
"6","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved 10% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On DFMA Thread Instructions Executed","inst/cycle","72",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On FFMA Thread Instructions Executed","inst/cycle","4608",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On DFMA Thread Instructions Executed Per Cycle","inst/cycle","0",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On FFMA Thread Instructions Executed Per Cycle","inst/cycle","410.35",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical Predicated-On FFMA Operations","inst","9216",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","SM Frequency","Ghz","2.40",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","DRAM Frequency","Ghz","13.79",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical Predicated-On DFMA Operations","inst","144",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","SM Frequency","Ghz","2.40",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","DRAM Frequency","Ghz","13.79",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FFMA Operations Per Cycle","inst","820.70",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","SM Frequency","Ghz","2.40",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FADD Thread Instructions Executed Per Cycle","inst/cycle","102.59",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FMUL Thread Instructions Executed Per Cycle","inst/cycle","12.82",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","DRAM Bandwidth","Gbyte/s","100.02",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DFMA Operations Per Cycle","inst","0",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","SM Frequency","Ghz","2.40",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DADD Thread Instructions Executed Per Cycle","inst/cycle","0",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DMUL Thread Instructions Executed Per Cycle","inst/cycle","0",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","DRAM Bandwidth","Gbyte/s","100.02",
"7","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved 10% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On DFMA Thread Instructions Executed","inst/cycle","72",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On FFMA Thread Instructions Executed","inst/cycle","4608",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On DFMA Thread Instructions Executed Per Cycle","inst/cycle","0",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On FFMA Thread Instructions Executed Per Cycle","inst/cycle","409.72",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical Predicated-On FFMA Operations","inst","9216",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","SM Frequency","Ghz","2.40",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","DRAM Frequency","Ghz","13.79",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical Predicated-On DFMA Operations","inst","144",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","SM Frequency","Ghz","2.40",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","DRAM Frequency","Ghz","13.79",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FFMA Operations Per Cycle","inst","819.44",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","SM Frequency","Ghz","2.40",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FADD Thread Instructions Executed Per Cycle","inst/cycle","102.43",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FMUL Thread Instructions Executed Per Cycle","inst/cycle","12.80",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.61",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DFMA Operations Per Cycle","inst","0",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","SM Frequency","Ghz","2.40",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DADD Thread Instructions Executed Per Cycle","inst/cycle","0",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DMUL Thread Instructions Executed Per Cycle","inst/cycle","0",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.61",
"8","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved 10% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On DFMA Thread Instructions Executed","inst/cycle","72",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On FFMA Thread Instructions Executed","inst/cycle","4608",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On DFMA Thread Instructions Executed Per Cycle","inst/cycle","0",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On FFMA Thread Instructions Executed Per Cycle","inst/cycle","410.89",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical Predicated-On FFMA Operations","inst","9216",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","SM Frequency","Ghz","2.40",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","DRAM Frequency","Ghz","13.79",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical Predicated-On DFMA Operations","inst","144",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","SM Frequency","Ghz","2.40",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","DRAM Frequency","Ghz","13.79",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FFMA Operations Per Cycle","inst","821.77",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","SM Frequency","Ghz","2.40",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FADD Thread Instructions Executed Per Cycle","inst/cycle","102.72",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FMUL Thread Instructions Executed Per Cycle","inst/cycle","12.84",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","DRAM Bandwidth","Gbyte/s","100.78",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DFMA Operations Per Cycle","inst","0",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","SM Frequency","Ghz","2.40",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DADD Thread Instructions Executed Per Cycle","inst/cycle","0",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DMUL Thread Instructions Executed Per Cycle","inst/cycle","0",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","DRAM Bandwidth","Gbyte/s","100.78",
"9","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved 10% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On DFMA Thread Instructions Executed","inst/cycle","72",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On FFMA Thread Instructions Executed","inst/cycle","4608",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On DFMA Thread Instructions Executed Per Cycle","inst/cycle","0",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On FFMA Thread Instructions Executed Per Cycle","inst/cycle","407.60",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical Predicated-On FFMA Operations","inst","9216",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","SM Frequency","Ghz","2.40",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","DRAM Frequency","Ghz","13.79",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical Predicated-On DFMA Operations","inst","144",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","SM Frequency","Ghz","2.40",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","DRAM Frequency","Ghz","13.79",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FFMA Operations Per Cycle","inst","815.19",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","SM Frequency","Ghz","2.40",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FADD Thread Instructions Executed Per Cycle","inst/cycle","101.90",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FMUL Thread Instructions Executed Per Cycle","inst/cycle","12.74",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.48",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DFMA Operations Per Cycle","inst","0",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","SM Frequency","Ghz","2.40",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DADD Thread Instructions Executed Per Cycle","inst/cycle","0",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DMUL Thread Instructions Executed Per Cycle","inst/cycle","0",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.48",
"10","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved 10% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On DFMA Thread Instructions Executed","inst/cycle","72",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On FFMA Thread Instructions Executed","inst/cycle","4608",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On DFMA Thread Instructions Executed Per Cycle","inst/cycle","0",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On FFMA Thread Instructions Executed Per Cycle","inst/cycle","407.97",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical Predicated-On FFMA Operations","inst","9216",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","SM Frequency","Ghz","2.40",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","DRAM Frequency","Ghz","13.79",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical Predicated-On DFMA Operations","inst","144",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","SM Frequency","Ghz","2.40",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","DRAM Frequency","Ghz","13.79",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FFMA Operations Per Cycle","inst","815.95",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","SM Frequency","Ghz","2.40",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FADD Thread Instructions Executed Per Cycle","inst/cycle","101.99",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FMUL Thread Instructions Executed Per Cycle","inst/cycle","12.75",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.91",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DFMA Operations Per Cycle","inst","0",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","SM Frequency","Ghz","2.40",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DADD Thread Instructions Executed Per Cycle","inst/cycle","0",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DMUL Thread Instructions Executed Per Cycle","inst/cycle","0",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.91",
"11","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved 10% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On DFMA Thread Instructions Executed","inst/cycle","72",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Theoretical Predicated-On FFMA Thread Instructions Executed","inst/cycle","4608",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On DFMA Thread Instructions Executed Per Cycle","inst/cycle","0",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","","Predicated-On FFMA Thread Instructions Executed Per Cycle","inst/cycle","408.48",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical Predicated-On FFMA Operations","inst","9216",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","SM Frequency","Ghz","2.40",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Roofline","DRAM Frequency","Ghz","13.79",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical Predicated-On DFMA Operations","inst","144",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","SM Frequency","Ghz","2.40",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","Theoretical DRAM Bytes Accessible","byte/cycle","32",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Roofline","DRAM Frequency","Ghz","13.79",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FFMA Operations Per Cycle","inst","816.96",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","SM Frequency","Ghz","2.40",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FADD Thread Instructions Executed Per Cycle","inst/cycle","102.12",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","Predicated-On FMUL Thread Instructions Executed Per Cycle","inst/cycle","12.77",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Single Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.71",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DFMA Operations Per Cycle","inst","0",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","SM Frequency","Ghz","2.40",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DADD Thread Instructions Executed Per Cycle","inst/cycle","0",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","Predicated-On DMUL Thread Instructions Executed Per Cycle","inst/cycle","0",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","GPU Speed Of Light Roofline Chart","Double Precision Achieved Value","DRAM Bandwidth","Gbyte/s","98.71",
"12","508817","cutlass_gemm_tunable2","127.0.0.1","void Kernel<Gemm<MmaPipelined<GemmShape<128, 256, 32>, PredicatedTileIterator<MatrixShape<128, 32>, half_t, RowMajor, 1, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<128, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<32, 128>, 256, PitchLinearShape<4, 8>, 8>, 16>, PredicatedTileIterator<MatrixShape<32, 256>, half_t, RowMajor, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 8, 0, NoPermute>, RegularTileIterator<MatrixShape<32, 256>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, 0, PitchLinearWarpRakedThreadMap<PitchLinearShape<256, 32>, 256, PitchLinearShape<8, 4>, 8>, 16>, float, RowMajor, MmaPolicy<MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, MatrixShape<0, 0>, MatrixShape<0, 0>, 1>, NumericArrayConverter<half_t, half_t, 16, 2, Identity>, NumericArrayConverter<half_t, half_t, 32, 2, Identity>, bool>, Epilogue<GemmShape<128, 256, 32>, MmaVoltaTensorOp<GemmShape<64, 64, 32>, half_t, RowMajorVoltaTensorOpMultiplicandCrosswise<16, 32>, half_t, RowMajorVoltaTensorOpMultiplicandBCongruous<16>, float, RowMajor, MmaTensorOpPolicy<Mma<GemmShape<16, 16, 4>, 32, half_t, RowMajor, half_t, RowMajor, float, RowMajor, OpMultiplyAdd>, MatrixShape<1, 1>>, bool>, 1, PredicatedTileIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>, float, 0, NoPermute, 0>, FragmentIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, Array<float, 8, 1>, RowMajor>, TileIteratorTensorOp<GemmShape<64, 64, 32>, GemmShape<16, 16, 4>, float, RowMajor>, SharedLoadIterator<OutputTileOptimalThreadMap<OutputTileShape<256, 8, 2, 1, 1>, OutputTileShape<1, 8, 1, 1, 8>, 256, 1, 32>::CompactedThreadMap, float, 4>, LinearCombination<float, 1, float, float, 0, 2, float>, MatrixShape<0, 8>, 1, 1>, GemmIdentityThreadblockSwizzle<1>, 0>>(Params)","1","7","(256, 1, 1)","(32, 16, 1)","0","12.0","SpeedOfLight_RooflineChart","","","","","SOLFPRoofline","INF","The ratio of peak float (FP32) to double (FP64) performance on this device is 64:1. The workload achieved 10% of this device's FP32 peak performance and 0% of its FP64 peak performance. See the Profiling Guide (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#roofline) for more details on roofline analysis.","",""
